{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.cuda.amp.autocast_mode import autocast\n",
    "from torch.cuda.amp.grad_scaler import GradScaler\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = 'Music_Classifier'\n",
    "\n",
    "with open('data/features2', 'rb') as f:\n",
    "    sfeats = pickle.load(f)\n",
    "\n",
    "with open('data/2rand140', 'rb') as f:\n",
    "    audio_data = pickle.load(f)\n",
    "\n",
    "with open('data/mcm140', 'rb') as f:\n",
    "    mmtrx = pickle.load(f).astype(np.float16)\n",
    "\n",
    "np.random.shuffle(audio_data)\n",
    "counts = collections.Counter([x[1][0] for x in audio_data])\n",
    "sfeats = {x[1]: x[0] for x in sfeats}\n",
    "#audio_data = [(((torch.tensor(x[0], dtype=torch.float32) - mmtrx).unsqueeze(0), torch.tensor(sfeats[x[1][0]], dtype=torch.float32).unsqueeze(0)), x[1][1]) for x in audio_data]\n",
    "blur = torchvision.transforms.GaussianBlur(3, sigma=(0.1, 2.0))\n",
    "erase = torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.8, 1.2), value=0, inplace=False)\n",
    "crop = torchvision.transforms.RandomResizedCrop((140, 128), scale=(0.84, 1.0))\n",
    "affine = torchvision.transforms.RandomAffine(0, translate=(0.2, 0), scale=(0.86, 1.14), shear=None, fill=0)\n",
    "invert = torchvision.transforms.RandomInvert()\n",
    "transforms = [blur, erase, crop, affine, invert]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def group_predict(adata: list[list[np.ndarray]], model: nn.Module) -> list[tuple[int, int]]:\n",
    "    predictions = []\n",
    "    model.to('cuda')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for song in adata:\n",
    "            frames = [(torch.tensor(frame, dtype=torch.float32) - mmtrx).unsqueeze(0).unsqueeze(0) for frame in song[0]]\n",
    "            results = []\n",
    "            for frame in frames:\n",
    "                frame.to('cuda')\n",
    "                results.append(torch.nn.functional.softmax(*model(frame), dim=0).tolist())\n",
    "            #results = [w for w in results if np.max(w) > np.max(results) * 0.333]\n",
    "            scores = [round(sum(w), 4) for w in  np.array(results).T]\n",
    "            predictions.append((song[1], scores.index(np.max(scores))))\n",
    "    model.to('cpu')\n",
    "    return predictions\n",
    "\n",
    "def aug_imgs(img_data: list[tuple[torch.Tensor, int]]) -> list[tuple[torch.Tensor, int]]:\n",
    "    aug_count = int(len(img_data) * 0.3678)\n",
    "    change = img_data[:aug_count]\n",
    "    final = img_data[aug_count:]\n",
    "    change = [((x[0] + 55).to(torch.uint8), x[1], x[1]) for x in change]\n",
    "    new_pack = []\n",
    "    for item in change:\n",
    "        label = item[1], item[2]\n",
    "        img = np.random.choice(transforms)(item[0])\n",
    "        if img.size() != (140, 128):\n",
    "            img = torchvision.transforms.functional.resize(img, (140, 128))\n",
    "        new_pack.append((img, label))\n",
    "    new_pack = [(x[0].to(torch.float32) - 55, x[1]) for x in new_pack]\n",
    "    final.extend(new_pack)\n",
    "    return final\n",
    "\n",
    "class Mini3(nn.Module):\n",
    "\n",
    "    def __init__(self, ftrs):\n",
    "        super(Mini3, self).__init__()\n",
    "        self.dcnv = nn.Conv2d(ftrs, ftrs // 2, 1)\n",
    "        self.cnv = nn.Conv2d(ftrs // 2, ftrs // 2, 3, 1, 1, bias=False)\n",
    "        self.ucnv = nn.Conv2d(ftrs // 2, ftrs, 1)\n",
    "        self.nrm = nn.BatchNorm2d(ftrs // 2)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.dcnv(x))\n",
    "        x = self.act(self.nrm(self.cnv(x)))\n",
    "        x = self.act(self.ucnv(x))\n",
    "        return x\n",
    "\n",
    "class ReStep(nn.Module):\n",
    "\n",
    "    def __init__(self, ftrs, poolks, final=False):\n",
    "        super(ReStep, self).__init__()\n",
    "        self.cnv1 = Mini3(ftrs)\n",
    "        self.cnv2 = Mini3(ftrs)\n",
    "        self.cnv3 = Mini3(ftrs)\n",
    "        self.dscale = nn.Conv2d(ftrs, ftrs, 1, poolks, bias=False)\n",
    "        if final:\n",
    "            self.uscale = nn.Conv2d(ftrs, ftrs, 1, 1)\n",
    "        else:\n",
    "            self.uscale = nn.Conv2d(ftrs, ftrs * 2, 1, 1)\n",
    "        self.inrm = nn.BatchNorm2d(ftrs)\n",
    "        self.mxpool = nn.MaxPool2d(poolks, poolks)\n",
    "        self.iact = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.cnv1(x)\n",
    "        x = self.cnv2(x)\n",
    "        x = self.mxpool(x)\n",
    "        x = self.iact(self.inrm(torch.add(x, self.dscale(res))))\n",
    "        res = x\n",
    "        x = self.cnv3(x)\n",
    "        x = self.iact(self.inrm(torch.add(x, res)))\n",
    "        x = self.iact(self.uscale(x))\n",
    "        return x\n",
    "\n",
    "class MusCls(nn.Module):\n",
    "\n",
    "    def __init__(self, step_1_ftrs: int, step_2_ftrs: int, step_3_ftrs: int, step_4_ftrs: int):\n",
    "        #torch.manual_seed(1024)\n",
    "        torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "        super(MusCls, self).__init__()\n",
    "        self.final_ftrs = step_4_ftrs // 2\n",
    "        self.ecnv1 = nn.Conv2d(1, step_1_ftrs, 3, 1, 1)\n",
    "        self.ecnv2 = nn.Conv2d(step_1_ftrs, step_1_ftrs, 3, 1, 1)\n",
    "        self.ecnv3 = nn.Conv2d(step_1_ftrs, step_1_ftrs, 3, 1, 1)\n",
    "        self.fcnv1 = nn.Conv2d(step_4_ftrs, self.final_ftrs, 3, 1, 1, bias=False)\n",
    "        self.fcnv2 = nn.Conv2d(step_4_ftrs, self.final_ftrs, 3, 1, 1, bias=False)\n",
    "        self.fcnv3 = nn.Conv2d(step_4_ftrs, self.final_ftrs, 3, 1, 1, bias=False)\n",
    "        self.nrm1 = nn.BatchNorm2d(self.final_ftrs)\n",
    "        self.nrm2 = nn.BatchNorm2d(self.final_ftrs)\n",
    "        self.nrm3 = nn.BatchNorm2d(self.final_ftrs)\n",
    "        self.lstep1 = ReStep(step_1_ftrs, (1, 2))\n",
    "        self.lstep2 = ReStep(step_2_ftrs, (1, 2))\n",
    "        self.lstep3 = ReStep(step_3_ftrs, 2, True)\n",
    "        self.lstep4 = ReStep(step_4_ftrs, 2, True)\n",
    "        self.mstep1 = ReStep(step_1_ftrs, (1, 2))\n",
    "        self.mstep2 = ReStep(step_2_ftrs, 2)\n",
    "        self.mstep3 = ReStep(step_3_ftrs, 2, True)\n",
    "        self.mstep4 = ReStep(step_4_ftrs, 2, True)\n",
    "        self.hstep1 = ReStep(step_1_ftrs, 2)\n",
    "        self.hstep2 = ReStep(step_2_ftrs, 2)\n",
    "        self.hstep3 = ReStep(step_3_ftrs, 2, True)\n",
    "        self.hstep4 = ReStep(step_4_ftrs, 2, True)\n",
    "        self.flin = nn.Linear(self.final_ftrs * 9 * 3, self.final_ftrs)\n",
    "        self.flin2 = nn.Linear(self.final_ftrs, 19)\n",
    "        self.act = nn.ELU()\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fmxpool = nn.AdaptiveAvgPool2d(3)\n",
    "        self.drop = nn.Dropout2d(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.ecnv1(x))\n",
    "        x = self.act(self.ecnv2(x))\n",
    "        x = self.act(self.ecnv3(x))\n",
    "        x = self.drop(x)\n",
    "        lows = x[:,:, :16, :]\n",
    "        mids = x[:,:, 14:62, :]\n",
    "        highs = x[:,:, 60:, :]\n",
    "        for i, step in enumerate([\n",
    "                (self.lstep1, self.mstep1, self.hstep1),\n",
    "                (self.lstep2, self.mstep2, self.hstep2),\n",
    "                (self.lstep3, self.mstep3, self.hstep3),\n",
    "                (self.lstep4, self.mstep4, self.hstep4)\n",
    "            ]):\n",
    "            lows = step[0](lows)\n",
    "            mids = step[1](mids)\n",
    "            highs = step[2](highs)\n",
    "            if i >= 2:\n",
    "                lows = self.drop(lows)\n",
    "                mids = self.drop(mids)\n",
    "                highs = self.drop(highs)\n",
    "        lows = self.act(self.nrm1(self.fcnv1(lows)))\n",
    "        mids = self.act(self.nrm2(self.fcnv2(mids)))\n",
    "        highs = self.act(self.nrm3(self.fcnv3(highs)))\n",
    "        lows = self.flat(self.fmxpool(lows))\n",
    "        mids = self.flat(self.fmxpool(mids))\n",
    "        highs = self.flat(self.fmxpool(highs))\n",
    "        x = torch.cat((lows, mids, highs), 1)\n",
    "        x = self.flin2(self.act(self.flin(x)))\n",
    "        return x\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model: nn.Module, model_name: str,  learning_rate: float, weight_decay: float, save_threshold: float) -> None:\n",
    "        self.model = model.to('cuda')\n",
    "        self.save_threshold = save_threshold\n",
    "        self.optimizer = torch.optim.NAdam(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.scaler = GradScaler(enabled=True)\n",
    "        self.model_name = model_name\n",
    "        self.tblog = SummaryWriter(log_dir=f'C:/Users/BBA/Coding/tblogs/{proj_name}/{model_name}')\n",
    "        self.tbatch_counter = 0\n",
    "        self.vbatch_counter = 0\n",
    "\n",
    "    def split_data(self, dataset: list[tuple[torch.Tensor, int]], ratio: float, splits: int) -> tuple[list[list[tuple[torch.Tensor, int]]], list[tuple[torch.Tensor, int]]]:\n",
    "        vdata = []\n",
    "        for x in counts.items():\n",
    "            gcounter = 0\n",
    "            i = 0\n",
    "            while gcounter < int(x[1] * ratio):\n",
    "                if dataset[i][1] == x[0]:\n",
    "                    vdata.append(dataset.pop(i))\n",
    "                    gcounter += 1\n",
    "                i += 1\n",
    "        tdata = [dataset[(x - 1) * int(len(dataset) / splits) : x * int(len(dataset) / splits)] for x in range(1, splits + 1)]\n",
    "        return tdata, vdata\n",
    "\n",
    "    def _train(self, dataset: list[tuple[torch.Tensor, int]]):\n",
    "        total_loss = 0\n",
    "        for i, x in enumerate(dataset):\n",
    "            with autocast(enabled=True):\n",
    "                data, labels = x[0].to('cuda'), x[1].to('cuda')\n",
    "                results = self.model(data)\n",
    "                loss = self.loss_function(results, labels)\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            total_loss += loss.item()\n",
    "            self.optimizer.zero_grad()\n",
    "            self.tblog.add_scalar('Train Loss/Batch', total_loss / (i + 1), self.tbatch_counter)\n",
    "            self.tbatch_counter += 1\n",
    "        return total_loss / len(dataset)\n",
    "\n",
    "    def _validate(self, dataset: list[tuple[torch.Tensor, int]]):\n",
    "        total_loss = 0\n",
    "        accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for i, x in enumerate(dataset):\n",
    "                correct = 0\n",
    "                data, labels = x[0].to('cuda'), x[1].to('cuda')\n",
    "                results = self.model(data)\n",
    "                for j, w in enumerate([torch.nn.functional.softmax(y, dim=0).argmax() for y in results]):\n",
    "                    if w == labels[j]:\n",
    "                        correct += 1\n",
    "                accuracy += correct / self.batch_size\n",
    "                total_loss += self.loss_function(results, labels).item()\n",
    "                self.tblog.add_scalar('Validate Loss/Batch', total_loss / (i + 1), self.vbatch_counter)\n",
    "                self.vbatch_counter += 1\n",
    "        return total_loss / len(dataset), accuracy / len(dataset)\n",
    "\n",
    "    def train_model(self, dataset: list[tuple[torch.Tensor, int]], target_epochs: int, batch_size: int, ratio: float, val: bool, splits: int, aug_lr: float, aug_epochs: list[int]):\n",
    "        self.batch_size = batch_size\n",
    "        samples = len(dataset)\n",
    "        train_data, val_data = self.split_data(dataset, ratio, splits)\n",
    "        for ep in range(target_epochs):\n",
    "            for i, group in enumerate(train_data):\n",
    "                self.batches_per_group = int(int(samples * (1 - ratio)) / splits / self.batch_size)\n",
    "                if ep in aug_epochs:\n",
    "                    for x in self.optimizer.param_groups:\n",
    "                        x['lr'] = aug_lr\n",
    "                    aug_data = aug_imgs(group.copy())\n",
    "                    tdata = DataLoader(aug_data, batch_size=self.batch_size, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "                else:\n",
    "                    tdata = DataLoader(group, batch_size=self.batch_size, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "                self.model.train(True)\n",
    "                train_loss = self._train(tdata)\n",
    "                if not val:\n",
    "                    print(f'Status at batch {self.batches_per_group * (1 + i)},\\tTLoss: {round(float(train_loss), 5)} TAccuracy {round(2.7182818**-float(train_loss) * 100, 5)}%')\n",
    "                if val:\n",
    "                    vdata = DataLoader(val_data, batch_size=self.batch_size, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "                    self.model.train(False)\n",
    "                    val_loss, val_acc = self._validate(vdata)\n",
    "                    print(f'Status at batch {self.batches_per_group * (1 + i)},\\tTLoss: {round(float(train_loss), 5)}\\tTPAccuracy {round(2.7182818**-float(train_loss) * 100, 5)}%\\tVLoss: {round(float(val_loss), 5)}\\tVGAccuracy {round(float(val_acc) * 100, 5)}%\\tVPAccuracy {round(2.7182818**-float(val_loss) * 100, 5)}%')\n",
    "                    if val_loss < self.save_threshold:\n",
    "                        self.save_threshold = val_loss\n",
    "                        torch.save(self.model.state_dict(), f'models/{self.model_name}')\n",
    "        self.model = self.model.to('cpu')\n",
    "        del dataset\n",
    "        self.tblog.close()\n",
    "        torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_model = MusCls(32, 64, 128, 128)\n",
    "av_model.load_state_dict(torch.load('models/mscls_34'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1378 / 1982\n",
      "69.52573158425832 %\n"
     ]
    }
   ],
   "source": [
    "dpack = 'btest140'\n",
    "with open(f'data/{dpack}', 'rb') as f:\n",
    "    tdata = pickle.load(f)\n",
    "\n",
    "with open(f'data/mcm140', 'rb') as f:\n",
    "    mmtrx = torch.tensor(pickle.load(f), dtype=torch.float32)\n",
    "\n",
    "predictions = group_predict(tdata, av_model)\n",
    "real_l = [x[1] for x in tdata]\n",
    "score = 0\n",
    "for i, x in enumerate(predictions):\n",
    "    #print(x, real_l[i])\n",
    "    if x[1] == real_l[i]:\n",
    "        score += 1\n",
    "print(score, '/', len(tdata))\n",
    "print(100 * (score / len(tdata)), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections.Counter(real_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpack = 'test140'\n",
    "\n",
    "with open(f'data/{dpack}', 'rb') as f:\n",
    "    tdata = pickle.load(f)\n",
    "\n",
    "with open(f'data/mcm140', 'rb') as f:\n",
    "    mmtrx = torch.tensor(pickle.load(f), dtype=torch.float32)\n",
    "\n",
    "predictions = group_predict(tdata, av_model)\n",
    "filename = '3mod3'\n",
    "\n",
    "with open(f'predictions/{filename}.csv', 'wt') as f:\n",
    "    f.writelines(['song_id,genre_id\\n'])\n",
    "    f.writelines([f'{x[0].lstrip(\"0\").rstrip(\".ogg\")},{x[1]}\\n' for x in predictions])\n",
    "    f.writelines(['24013,0\\n', '22612,1\\n'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "489c9a9a56e86705d77b3b0d6716b8bf16bea0f07ee042748988e2e93c15e7dd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

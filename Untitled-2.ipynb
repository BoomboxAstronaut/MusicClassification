{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BBA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_masked\\__init__.py:223: UserWarning: Failed to initialize NumPy: module compiled against API version 0xf but this version of numpy is 0xe (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  example_input = torch.tensor([[-3, -2, -1], [0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import librosa\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp.autocast_mode import autocast\n",
    "from torch.cuda.amp.grad_scaler import GradScaler\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpack = 'xgroup4'\n",
    "\n",
    "with open(dpack, 'rb') as f:\n",
    "    audio_data = pickle.load(f)\n",
    "\n",
    "counts = collections.Counter([x[1] for x in audio_data])\n",
    "total = np.sum([x for x in counts.values()])\n",
    "audio_data = [(torch.tensor([(np.float32(x[0]) - np.mean(x[0])) / 80], dtype=torch.float32), torch.tensor(x[1], dtype=torch.int64)) for x in audio_data]\n",
    "lblwgts = [counts[x] / total for x in range(19)]\n",
    "lblwgts = [((((1/19) / x) + 1/19) / 2) + 0.3678 for x in lblwgts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReStep(nn.Module):\n",
    "\n",
    "    def __init__(self, ftrs, up_ftrs):\n",
    "        super(ReStep, self).__init__()\n",
    "        self.icnv = nn.Conv2d(ftrs, ftrs, 3, 1, 1)\n",
    "        self.idcnv = nn.Conv2d(ftrs, ftrs, 1)\n",
    "        self.irescal = nn.Conv2d(ftrs, ftrs, 1, 2)\n",
    "        self.iupscal = nn.Conv2d(ftrs, up_ftrs, 3, 1, 1)\n",
    "        self.inrm = nn.BatchNorm2d(ftrs)\n",
    "        self.imxpool = nn.MaxPool2d(2, 2)\n",
    "        self.iact = nn.ELU()\n",
    "        self.drop = nn.Dropout(0.16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.iact(self.inrm(self.icnv(x)))\n",
    "        x = self.iact(self.inrm(self.icnv(x)))\n",
    "        x = self.imxpool(x)\n",
    "        #x = self.drop(x)\n",
    "        x = self.iact(torch.add(x, self.inrm(self.irescal(res))))\n",
    "        res = x\n",
    "        x = self.iact(self.icnv(x))\n",
    "        x = self.iact(self.idcnv(x))\n",
    "        x = self.iupscal(self.inrm(torch.add(x, res)))\n",
    "        return x\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self, step_1_ftrs: int, step_2_ftrs: int, step_3_ftrs: int, step_4_ftrs: int):\n",
    "        torch.manual_seed(1024)\n",
    "        torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.final_ftrs = step_4_ftrs\n",
    "        self.ecnv1 = nn.Conv2d(1, step_1_ftrs, 3, 1, 1)\n",
    "        self.ecnv2 = nn.Conv2d(step_1_ftrs, step_1_ftrs, 3, 1, 1)\n",
    "        self.fcnv = nn.Conv2d(self.final_ftrs, self.final_ftrs, 3, 1, 1)\n",
    "        self.act = nn.ELU()\n",
    "        self.nrm = nn.BatchNorm2d(self.final_ftrs)\n",
    "        self.fmxpool = nn.AdaptiveAvgPool2d(4)\n",
    "        self.drop = nn.Dropout(0.32)\n",
    "        self.flin = nn.Linear(self.final_ftrs * 16, self.final_ftrs * 2)\n",
    "        self.flin2 = nn.Linear(self.final_ftrs * 2, 19)\n",
    "        self.resloop = [ReStep(step_1_ftrs, step_2_ftrs), ReStep(step_2_ftrs, step_3_ftrs), ReStep(step_3_ftrs, step_4_ftrs), ReStep(step_4_ftrs, step_4_ftrs)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.ecnv1(x))\n",
    "        x = self.act(self.ecnv2(x))\n",
    "        for loop in self.resloop:\n",
    "            x = loop(x)\n",
    "        x = self.act(self.nrm(self.fcnv(x)))\n",
    "        x = self.fmxpool(x)\n",
    "        x = self.drop(x)\n",
    "        x = x.view(-1, self.final_ftrs * 16)\n",
    "        x = self.flin2(self.act(self.flin(x)))\n",
    "        return x\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model: nn.Module, optimizer: torch.optim, loss_function: nn.CrossEntropyLoss, learning_rate: float, weight_decay: float, label_weights):\n",
    "        self.gpu = torch.device('cuda')\n",
    "        self.model = model.cuda()\n",
    "        self.optimizer = optimizer(av_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        #self.loss_function = loss_function(weight=torch.tensor(label_weights, dtype=torch.float32))\n",
    "        self.loss_function = loss_function()\n",
    "        self.scaler = GradScaler(enabled=True)\n",
    "\n",
    "    def _split_data(self, adata, ratio, splits):\n",
    "        np.random.shuffle(adata)\n",
    "        vdata = []\n",
    "        for x in counts.items():\n",
    "            gcounter = 0\n",
    "            i = 0\n",
    "            while gcounter < int(x[1] * ratio):\n",
    "                if adata[i][1] != x[0]:\n",
    "                    vdata.append(adata.pop(i))\n",
    "                    gcounter += 1\n",
    "                i += 1\n",
    "        adata = [adata[(x - 1) * int(len(adata) / splits) : x * int(len(adata) / splits)] for x in range(1, splits + 1)]\n",
    "        adata = [[x, vdata] for x in adata]\n",
    "        return adata\n",
    "\n",
    "    def _train(self, dataset):\n",
    "        total_loss = 0\n",
    "        for x in dataset:\n",
    "            with autocast(enabled=True):\n",
    "                data, labels = x[0].to(self.gpu), x[1].to(self.gpu)\n",
    "                results = self.model(data)\n",
    "                loss = self.loss_function(results, labels)\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            total_loss += loss.item()\n",
    "            self.optimizer.zero_grad()\n",
    "        return total_loss / len(dataset)\n",
    "\n",
    "    def _validate(self, dataset):\n",
    "        total_loss = 0\n",
    "        accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for x in dataset:\n",
    "                correct = 0\n",
    "                data, labels = x[0].to(self.gpu), x[1].to(self.gpu)\n",
    "                results = self.model(data)\n",
    "                for i, x in enumerate([x.argmax() for x in results]):\n",
    "                    if x == labels[i]:\n",
    "                        correct += 1\n",
    "                accuracy += correct / 64\n",
    "                total_loss += self.loss_function(results, labels).item()\n",
    "        return total_loss / len(dataset), accuracy / len(dataset)\n",
    "\n",
    "    def train_model(self, dataset, target_epochs, ratio, model_name, val, splits):\n",
    "        self.cycle = round(time.time())\n",
    "        best_loss = 1.35\n",
    "        samples = len(dataset)\n",
    "        dataset = self._split_data(dataset, ratio, splits)\n",
    "        for _ in range(target_epochs):\n",
    "            for i, group in enumerate(dataset):\n",
    "                self.model.train(True)\n",
    "                np.random.shuffle(group[0])\n",
    "                tdata = iter(torch.utils.data.DataLoader(group[0], batch_size=64))\n",
    "                train_loss = self._train(tdata)\n",
    "                if not val:\n",
    "                    print(f'Status at batch {int((i+1) * int(samples * (1 - ratio)) / splits / 64)},\\tTLoss: {round(float(train_loss), 5)} TAccuracy {round(2.7182818**-float(train_loss) * 100, 5)}%')\n",
    "                if val:\n",
    "                    self.model.train(False)\n",
    "                    np.random.shuffle(group[1])\n",
    "                    vdata = iter(torch.utils.data.DataLoader(group[1], batch_size=64))\n",
    "                    val_loss, val_acc = self._validate(vdata)\n",
    "                    print(f'Status at batch {int((i+1) * int(samples * (1 - ratio)) / splits / 64)},\\tTLoss: {round(float(train_loss), 5)}\\tTAccuracy {round(2.7182818**-float(train_loss) * 100, 5)}%\\tVLoss: {round(float(val_loss), 5)}\\tVAccuracy {round(float(val_acc) * 100, 5)}%')\n",
    "                    if val_loss < best_loss:\n",
    "                        best_loss = val_loss\n",
    "                        torch.save(self.model.state_dict(), f'models/{model_name}')\n",
    "        self.model = self.model.cpu()\n",
    "        del dataset\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_model = FeatureExtractor(32, 64, 128, 256)\n",
    "av_model.load_state_dict(torch.load('models/mscls_03', map_location=\"cuda\"))\n",
    "#print(np.sum(sum(x.numel() for x in av_model.parameters() if x.requires_grad)))\n",
    "\n",
    "\n",
    "#trainer = Trainer(av_model, torch.optim.NAdam, nn.CrossEntropyLoss, 3e-4, 1e-5, lblwgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status at batch 466,\tTLoss: 1.10919\tTAccuracy 32.98271%\tVLoss: 1.00775\tVAccuracy 65.73486%\n",
      "Status at batch 933,\tTLoss: 1.09787\tTAccuracy 33.35821%\tVLoss: 1.0034\tVAccuracy 65.42969%\n",
      "Status at batch 466,\tTLoss: 0.98737\tTAccuracy 37.25546%\tVLoss: 0.99709\tVAccuracy 66.28418%\n",
      "Status at batch 933,\tTLoss: 0.98702\tTAccuracy 37.26867%\tVLoss: 1.00539\tVAccuracy 66.18652%\n",
      "Status at batch 466,\tTLoss: 0.90375\tTAccuracy 40.50479%\tVLoss: 0.99288\tVAccuracy 66.57715%\n",
      "Status at batch 933,\tTLoss: 0.91596\tTAccuracy 40.01337%\tVLoss: 1.00781\tVAccuracy 65.55176%\n"
     ]
    }
   ],
   "source": [
    "trainer.train_model(audio_data, 3, 0.12, 'mscls_034', True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(av_model.state_dict(), 'models/mscls_033')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(filename: str, model: nn.Module, fmax, samples=4):\n",
    "    with open(f'{filename}', 'rb') as f:\n",
    "        sraw, sr = librosa.load(f, sr=None)\n",
    "    scale = sr / 22050\n",
    "    model.cuda()\n",
    "    msgram = librosa.power_to_db(librosa.feature.melspectrogram(S=np.abs(librosa.stft(sraw, n_fft=int(2048 * scale)))**2, sr=sr, fmax=fmax), ref=np.max)\n",
    "    portions = []\n",
    "    if msgram.shape[1] < 128:\n",
    "        msgram = np.float32(Image.fromarray(np.uint8(msgram)).resize((128, 128)))\n",
    "    for i in range(round(msgram.shape[1] * 0.1),  round(msgram.shape[1] *0.9) - 5, round((msgram.shape[1] * 0.8) / samples)):\n",
    "        portions.append((np.uint8(np.abs(msgram[:, i:i+128])) * 2))\n",
    "    portions = [torch.tensor([[(x - np.mean(x)) / 80]], dtype=torch.float32) for x in portions]\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for x in portions:\n",
    "            x.to('cuda:0')\n",
    "            results.append(torch.nn.functional.softmax(*model(x), dim=0).tolist())\n",
    "    model.cpu()\n",
    "    results = [x for x in results if np.max(x) > np.max(results) * 0.666]\n",
    "    scores = [round(sum(x), 4) for x in  np.array(results).T]\n",
    "    guess = scores.index(np.max(scores))\n",
    "    return guess\n",
    "\n",
    "def group_predict(adata, model):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i, dset in enumerate(adata):\n",
    "            portions = [torch.tensor([[(np.float32(y) - np.mean(y)) / 80]], dtype=torch.float32) for y in dset[0]]\n",
    "            results = []\n",
    "            for z in portions:\n",
    "                z.to('cuda:0')\n",
    "                results.append(torch.nn.functional.softmax(*model(z), dim=0).tolist())\n",
    "            #results = [w for w in results if np.max(w) > np.max(results) * 0.3678]\n",
    "            scores = [round(sum(w), 4) for w in  np.array(results).T]\n",
    "            predictions.append((dset[1], scores.index(np.max(scores))))\n",
    "            if i % 512 == 0 and i != 0:\n",
    "                print(i)\n",
    "    model.cpu()\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [predict(f'testing/{x}', av_model, 4096, 5) for x in list(os.listdir(r'C:\\Users\\BBA\\Coding\\Audio\\Classification\\testing'))]\n",
    "real_l = [14, 14, 3, 3, 3, 6, 6, 7, 7, 0, 0, 0, 10, 10, 10, 2, 2, 2, 8, 8, 8, 5, 5, 5, 4, 4, 4, 1, 1, 1, 9, 9, 12, 12, 15, 15, 16, 16, 17, 17, 13, 13, 11, 11, 18, 18]\n",
    "real_g = 0\n",
    "for i, x in enumerate(predictions):\n",
    "    if x == real_l[i]:\n",
    "        real_g += 1\n",
    "    print(real_l[i], x)\n",
    "print(real_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "1024\n",
      "1536\n",
      "2048\n",
      "2560\n",
      "3072\n",
      "3584\n",
      "4096\n",
      "4608\n"
     ]
    }
   ],
   "source": [
    "dpack = 'tgroup1'\n",
    "with open(dpack, 'rb') as f:\n",
    "    audio_data = pickle.load(f)\n",
    "\n",
    "predictions = group_predict(audio_data, av_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_l = [14, 14, 3, 3, 3, 6, 6, 7, 7, 0, 0, 0, 10, 10, 10, 2, 2, 2, 8, 8, 8, 5, 5, 5, 4, 4, 4, 1, 1, 1, 9, 9, 12, 12, 15, 15, 16, 16, 17, 17, 13, 13, 11, 11, 18, 18]\n",
    "score = 0\n",
    "for i, x in enumerate(predictions):\n",
    "    print(x, real_l[i])\n",
    "    if x[1] == real_l[i]:\n",
    "        score += 1\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bba_preds.csv', 'wt') as f:\n",
    "    f.writelines([f'{x[0].lstrip(\"0\").rstrip(\".ogg\")},{x[1]}\\n' for x in predictions])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "489c9a9a56e86705d77b3b0d6716b8bf16bea0f07ee042748988e2e93c15e7dd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

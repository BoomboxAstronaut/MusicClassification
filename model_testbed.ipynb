{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BBA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_masked\\__init__.py:223: UserWarning: Failed to initialize NumPy: module compiled against API version 0xf but this version of numpy is 0xe (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  example_input = torch.tensor([[-3, -2, -1], [0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.cuda.amp.autocast_mode import autocast\n",
    "from torch.cuda.amp.grad_scaler import GradScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeatConv(nn.Module):\n",
    "\n",
    "    def __init__(self, fsize):\n",
    "        super(FeatConv, self).__init__()\n",
    "        self.cnv1 = nn.Conv2d(1, fsize, 3, 1, 1, bias=False)\n",
    "        self.cnv2 = nn.Conv2d(fsize, fsize, 3, 1, 1, bias=False)\n",
    "        self.cnv3 = nn.Conv2d(fsize, fsize, 3, 1, 1, bias=False)\n",
    "        self.icnv = nn.Conv2d(fsize, fsize * 2, 1, bias=False)\n",
    "        self.cnv4 = nn.Conv2d(fsize * 2, fsize * 2, 3, 1, 1, bias=False)\n",
    "        self.cnv5 = nn.Conv2d(fsize * 2, fsize * 2, 3, 1, 1, bias=False)\n",
    "        self.nrm1 = nn.BatchNorm2d(fsize)\n",
    "        self.nrm2 = nn.BatchNorm2d(fsize)\n",
    "        self.nrm3 = nn.BatchNorm2d(fsize)\n",
    "        self.nrmc1 = nn.BatchNorm2d(fsize)\n",
    "        self.nrmc2 = nn.BatchNorm2d(fsize * 2)\n",
    "        self.nrm4 = nn.BatchNorm2d(fsize * 2)\n",
    "        self.nrm5 = nn.BatchNorm2d(fsize * 2)\n",
    "        self.nrmi = nn.BatchNorm2d(fsize * 2)\n",
    "        self.fpool = nn.AdaptiveAvgPool2d(6)\n",
    "        self.act = nn.ELU()\n",
    "        self.flat = nn.Flatten()\n",
    "        self.drop = nn.Dropout2d(0.16)\n",
    "        self.ll1 = nn.Linear(2304, 512)\n",
    "        self.ll2 = nn.Linear(512, 128)\n",
    "        self.ll3 = nn.Linear(128, 19)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.nrm1(self.cnv1(x)))\n",
    "        res = x\n",
    "        x = self.act(self.nrm2(self.cnv2(x)))\n",
    "        x = self.act(self.nrm3(self.cnv3(x)))\n",
    "        x = self.act(self.nrmc1(torch.add(x, res)))\n",
    "        x = self.act(self.nrmi(self.icnv(x)))\n",
    "        res = x\n",
    "        x = self.act(self.nrm4(self.cnv4(x)))\n",
    "        x = self.act(self.nrm5(self.cnv5(x)))\n",
    "        x = self.act(self.nrmc2(torch.add(x, res)))\n",
    "        x = self.drop(x)\n",
    "        x = self.fpool(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.act(self.ll1(x))\n",
    "        x = self.act(self.ll2(x))\n",
    "        x = self.act(self.ll3(x))\n",
    "        return x\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model: nn.Module, model_name: str, lrn_rate1: float, wdecay1: float, save_threshold: float) -> None:\n",
    "        self.model = model.to('cuda')\n",
    "        self.save_threshold = save_threshold\n",
    "        self.lrn_rate1 = lrn_rate1\n",
    "        self.wdecay1 = wdecay1\n",
    "        self.optimizer = torch.optim.NAdam(self.model.parameters(), lr=lrn_rate1, weight_decay=wdecay1)\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.scaler = GradScaler(enabled=True)\n",
    "        self.model_name = model_name\n",
    "        self.tbatch_counter = 0\n",
    "        self.vbatch_counter = 0\n",
    "\n",
    "    def split_data(self, dataset: list[tuple[torch.Tensor, int]], ratio: float, splits):\n",
    "        vdata = []\n",
    "        counts = collections.Counter([x[1] for x in dataset])\n",
    "        for x in counts.items():\n",
    "            gcounter = 0\n",
    "            i = 0\n",
    "            while gcounter < int(x[1] * ratio):\n",
    "                if dataset[i][1] == x[0]:\n",
    "                    vdata.append(dataset.pop(i))\n",
    "                    gcounter += 1\n",
    "                i += 1\n",
    "        tdata = [dataset[(x - 1) * int(len(dataset) / splits) : x * int(len(dataset) / splits)] for x in range(1, splits + 1)]\n",
    "        return tdata, vdata\n",
    "\n",
    "    def _train(self, dataset):\n",
    "        total_loss = 0\n",
    "        self.model.train()\n",
    "        for x in dataset:\n",
    "            with autocast(enabled=True):\n",
    "                data, labels = x[0].to('cuda'), x[1].to('cuda')\n",
    "                results = self.model(data)\n",
    "                loss = self.loss_function(results, labels)\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            total_loss += loss.item()\n",
    "            self.optimizer.zero_grad()\n",
    "            self.tbatch_counter += 1\n",
    "        return total_loss / len(dataset)\n",
    "\n",
    "    def _validate(self, dataset):\n",
    "        total_loss = 0\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for x in dataset:\n",
    "                data, labels = x[0].to('cuda'), x[1].to('cuda')\n",
    "                results = self.model(data)\n",
    "                for j, w in enumerate([F.softmax(y, dim=0).argmax() for y in results]):\n",
    "                    predictions.append((labels[j], w))\n",
    "                total_loss += self.loss_function(results, labels).item()\n",
    "                self.vbatch_counter += 1\n",
    "        return total_loss / len(dataset), predictions\n",
    "\n",
    "    def train_model(self, dataset, target_epochs: int, batch_size: int, ratio: float, splits):\n",
    "        self.batch_size = batch_size\n",
    "        samples = len(dataset)\n",
    "        train_data, val_data = self.split_data(dataset, ratio, splits)\n",
    "        \n",
    "        for ep in range(target_epochs):\n",
    "            for i, group in enumerate(train_data):\n",
    "                self.batches_per_group = int(int(samples * (1 - ratio)) / self.batch_size)\n",
    "\n",
    "                tdata = DataLoader(group, batch_size=self.batch_size, shuffle=True)\n",
    "                train_loss = self._train(tdata)\n",
    "                vdata = DataLoader(val_data, batch_size=self.batch_size, shuffle=True)\n",
    "                val_loss, predictions = self._validate(vdata)\n",
    "\n",
    "                print(f'Status at batch {self.batches_per_group * (1 + i)},\\tTLoss: {round(float(train_loss), 5)}\\tVLoss: {round(float(val_loss), 5)}')\n",
    "                _ = print_metrics(predictions)\n",
    "\n",
    "                if val_loss < self.save_threshold:\n",
    "                    self.save_threshold = val_loss\n",
    "                    torch.save(self.model.state_dict(), f'models/{self.model_name}')\n",
    "\n",
    "        self.model = self.model.to('cpu')\n",
    "        del dataset\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def group_predict(adata: list[list[np.ndarray]], model: nn.Module) -> list[tuple[int, int]]:\n",
    "    predictions = []\n",
    "    model.to('cuda')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for song in adata:\n",
    "            results = []\n",
    "            for frame in song[0]:\n",
    "                spctr, ftr = frame[0].to('cuda'), frame[1].to('cuda')\n",
    "                results.append(torch.nn.functional.softmax(*model((spctr, ftr)), dim=0).tolist())\n",
    "            scores = [round(sum(w), 4) for w in  np.array(results).T]\n",
    "            predictions.append((song[1], scores.index(np.max(scores))))\n",
    "    model.to('cpu')\n",
    "    return predictions\n",
    "\n",
    "def print_metrics(predictions):\n",
    "    print(f'Label\\t\\tRecall\\t\\tPrecision\\tF1\\t\\tRatio')\n",
    "    metrics = []\n",
    "    total = len(predictions)\n",
    "    for x in range(19):\n",
    "        tp = 0\n",
    "        guesses = [y for y in predictions if y[1] == x]\n",
    "        actual = [y for y in predictions if y[0] == x]\n",
    "        for z in actual:\n",
    "            if z[0] == z[1]:\n",
    "                tp += 1\n",
    "        alen = len(actual)\n",
    "        glen = len(guesses)\n",
    "        if glen == 0 or alen == 0 or tp == 0:\n",
    "            alen += 1\n",
    "            glen += 1\n",
    "            tp += 1\n",
    "        recall = round(tp / alen, 3)\n",
    "        precis = round(tp / glen, 3)\n",
    "        f1 = round(2 * (precis * recall) / (precis + recall), 3)\n",
    "        metrics.append((alen, glen, tp))\n",
    "        print(f'{x}\\t\\t{recall}\\t\\t{precis}\\t\\t{f1}\\t\\t{tp}/{glen}/{alen}')\n",
    "    correct = sum([x[2] for x in metrics])\n",
    "    mprec = round(np.mean([x[2] / x[1] for x in metrics]), 4)\n",
    "    mrec = round(np.mean([x[2] / x[0] for x in metrics]), 4)\n",
    "    f1mac = round(2 * ((mprec * mrec) / (mprec**-1 + mrec**-1)), 4)\n",
    "    f1mic = round(correct / total, 4)\n",
    "    mcc = round((correct * total - sum([x[0] * x[1] for x in metrics])) / np.sqrt((total**2 - sum(x[0]**2 for x in metrics))*(total**2 - sum(x[1]**2 for x in metrics))), 4)\n",
    "    #ck = round((correct * total - sum([x[1] * x[0] for x in metrics])) / (total**2 - sum([x[1] * x[0] for x in metrics])), 3)\n",
    "    print('\\n')\n",
    "    print(f\"Macro Precision\\t\\t{mprec}\")\n",
    "    print(f'Macro Recall\\t\\t{mrec}')\n",
    "    print(f'F1 Macro\\t\\t{f1mac}')\n",
    "    print(f'F1 Micro\\t\\t{f1mic}')\n",
    "    print(f'MCC\\t\\t\\t{mcc}')\n",
    "    #print(f'CK\\t\\t\\t{ck}')\n",
    "    print(correct, '/', total)\n",
    "    return mprec, mrec, f1mac, f1mic, mcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fmodel\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/feats', 'rb') as f:\n",
    "    adata = pickle.load(f)\n",
    "with open('data/train_labels', 'rt') as f:\n",
    "    labels = f.readlines()\n",
    "labels = [x.split(',') for x in labels]\n",
    "labels = {x[1]: int(x[3]) for x in labels}\n",
    "adata = [(torch.tensor(x[0], dtype=torch.float32).unsqueeze(0), labels[x[1]]) for x in adata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1343539\n",
      "Status at batch 559,\tTLoss: 1.94697\tVLoss: 1.93246\n",
      "Label\t\tRecall\t\tPrecision\tF1\t\tRatio\n",
      "0\t\t0.215\t\t0.475\t\t0.296\t\t66/139/307\n",
      "1\t\t0.56\t\t0.276\t\t0.37\t\t173/626/309\n",
      "2\t\t0.442\t\t0.389\t\t0.414\t\t114/293/258\n",
      "3\t\t0.106\t\t0.463\t\t0.173\t\t19/41/179\n",
      "4\t\t0.737\t\t0.353\t\t0.477\t\t129/365/175\n",
      "5\t\t0.678\t\t0.328\t\t0.442\t\t82/250/121\n",
      "6\t\t0.051\t\t0.6\t\t0.094\t\t6/10/118\n",
      "7\t\t0.327\t\t0.291\t\t0.308\t\t34/117/104\n",
      "8\t\t0.021\t\t0.154\t\t0.037\t\t2/13/94\n",
      "9\t\t0.086\t\t0.7\t\t0.153\t\t7/10/81\n",
      "10\t\t0.013\t\t0.125\t\t0.024\t\t1/8/79\n",
      "11\t\t0.592\t\t0.468\t\t0.523\t\t29/62/49\n",
      "12\t\t0.95\t\t0.974\t\t0.962\t\t38/39/40\n",
      "13\t\t0.067\t\t0.25\t\t0.106\t\t2/8/30\n",
      "14\t\t0.067\t\t1.0\t\t0.126\t\t1/1/15\n",
      "15\t\t0.1\t\t1.0\t\t0.182\t\t1/1/10\n",
      "16\t\t0.1\t\t0.5\t\t0.167\t\t1/2/10\n",
      "17\t\t0.167\t\t1.0\t\t0.286\t\t1/1/6\n",
      "18\t\t0.5\t\t1.0\t\t0.667\t\t1/1/2\n",
      "\n",
      "\n",
      "Macro Precision\t\t0.5446\n",
      "Macro Recall\t\t0.3041\n",
      "F1 Macro\t\t0.0646\n",
      "F1 Micro\t\t0.3567\n",
      "MCC\t\t\t0.2866\n",
      "707 / 1982\n",
      "Status at batch 559,\tTLoss: 1.74906\tVLoss: 1.7086\n",
      "Label\t\tRecall\t\tPrecision\tF1\t\tRatio\n",
      "0\t\t0.573\t\t0.448\t\t0.503\t\t176/393/307\n",
      "1\t\t0.239\t\t0.278\t\t0.257\t\t74/266/309\n",
      "2\t\t0.721\t\t0.387\t\t0.504\t\t186/481/258\n",
      "3\t\t0.369\t\t0.337\t\t0.352\t\t66/196/179\n",
      "4\t\t0.674\t\t0.576\t\t0.621\t\t118/205/175\n",
      "5\t\t0.471\t\t0.456\t\t0.463\t\t57/125/121\n",
      "6\t\t0.178\t\t0.525\t\t0.266\t\t21/40/118\n",
      "7\t\t0.337\t\t0.443\t\t0.383\t\t35/79/104\n",
      "8\t\t0.043\t\t1.0\t\t0.082\t\t4/4/94\n",
      "9\t\t0.235\t\t0.594\t\t0.337\t\t19/32/81\n",
      "10\t\t0.076\t\t0.162\t\t0.103\t\t6/37/79\n",
      "11\t\t0.653\t\t0.571\t\t0.609\t\t32/56/49\n",
      "12\t\t1.0\t\t0.741\t\t0.851\t\t40/54/40\n",
      "13\t\t0.032\t\t0.5\t\t0.06\t\t1/2/31\n",
      "14\t\t0.067\t\t1.0\t\t0.126\t\t1/1/15\n",
      "15\t\t0.1\t\t1.0\t\t0.182\t\t1/1/10\n",
      "16\t\t0.556\t\t0.385\t\t0.455\t\t5/13/9\n",
      "17\t\t0.167\t\t1.0\t\t0.286\t\t1/1/6\n",
      "18\t\t0.5\t\t1.0\t\t0.667\t\t1/1/2\n",
      "\n",
      "\n",
      "Macro Precision\t\t0.6001\n",
      "Macro Recall\t\t0.3679\n",
      "F1 Macro\t\t0.1007\n",
      "F1 Micro\t\t0.4258\n",
      "MCC\t\t\t0.3582\n",
      "844 / 1982\n",
      "Status at batch 559,\tTLoss: 1.68268\tVLoss: 1.71135\n",
      "Label\t\tRecall\t\tPrecision\tF1\t\tRatio\n",
      "0\t\t0.586\t\t0.373\t\t0.456\t\t180/483/307\n",
      "1\t\t0.382\t\t0.337\t\t0.358\t\t118/350/309\n",
      "2\t\t0.609\t\t0.458\t\t0.523\t\t157/343/258\n",
      "3\t\t0.33\t\t0.41\t\t0.366\t\t59/144/179\n",
      "4\t\t0.709\t\t0.473\t\t0.567\t\t124/262/175\n",
      "5\t\t0.595\t\t0.419\t\t0.492\t\t72/172/121\n",
      "6\t\t0.11\t\t0.565\t\t0.184\t\t13/23/118\n",
      "7\t\t0.212\t\t0.458\t\t0.29\t\t22/48/104\n",
      "8\t\t0.043\t\t0.19\t\t0.07\t\t4/21/94\n",
      "9\t\t0.284\t\t0.442\t\t0.346\t\t23/52/81\n",
      "10\t\t0.013\t\t1.0\t\t0.026\t\t1/1/80\n",
      "11\t\t0.653\t\t0.653\t\t0.653\t\t32/49/49\n",
      "12\t\t0.7\t\t1.0\t\t0.824\t\t28/28/40\n",
      "13\t\t0.067\t\t0.667\t\t0.122\t\t2/3/30\n",
      "14\t\t0.067\t\t0.5\t\t0.118\t\t1/2/15\n",
      "15\t\t0.1\t\t1.0\t\t0.182\t\t1/1/10\n",
      "16\t\t0.111\t\t0.333\t\t0.167\t\t1/3/9\n",
      "17\t\t0.167\t\t1.0\t\t0.286\t\t1/1/6\n",
      "18\t\t0.5\t\t1.0\t\t0.667\t\t1/1/2\n",
      "\n",
      "\n",
      "Macro Precision\t\t0.5936\n",
      "Macro Recall\t\t0.3281\n",
      "F1 Macro\t\t0.0823\n",
      "F1 Micro\t\t0.4238\n",
      "MCC\t\t\t0.3524\n",
      "840 / 1982\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_session = '0'\n",
    "fmodel = FeatConv(32)\n",
    "print(sum(x.numel() for x in fmodel.parameters() if x.requires_grad))\n",
    "\n",
    "#av_model.load_state_dict(torch.load('models/mscls_x'))\n",
    "trainer = Trainer(fmodel, f'ftest_{train_session}', 3e-4, 1e-5, 1.4)\n",
    "trainer.train_model(adata.copy(), 3, 32, 0.1, 1)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "489c9a9a56e86705d77b3b0d6716b8bf16bea0f07ee042748988e2e93c15e7dd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
